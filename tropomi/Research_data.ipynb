{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research on the post-it requirements list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding leakages data labels\n",
    "\n",
    "#### By : Dirk and Kenneth\n",
    "\n",
    "We found \n",
    "https://www.edf.org/climate/methane-research-series-16-studies\n",
    "\n",
    "The following paper analyzes the amount of gas leaked in the transport and storage sector in the US. It uses the leakage data from on-site measurements in sites across the US.\n",
    "Methane Emissions from the Natural Gas Transmission and Storage System in the United States\n",
    "https://pubs.acs.org/doi/abs/10.1021/acs.est.5b01669\n",
    "\n",
    "We found the input data used:\n",
    "es5b01669_si_002.zip (3.42 MB)\n",
    "The data was collected in 2012. If we find the locations of the sites, we can try to combine these measurements with the tropomi data. I sent an email to the main writer of this paper to ask about the locations or names of the sites they\n",
    "\n",
    "#### Parameters for gas leakage\n",
    "\n",
    "We found this paper which says according to the American Petroleum Institute document \"RP 1130\", Leak Detection Systems are divided into internally based LDS and externally based LDS. Internally based systems use field instrumentation (for example flow, pressure or fluid temperature sensors) to monitor internal pipeline parameters. Externally based systems use a different set of field instrumentation (for example infrared radiometers or thermal cameras, vapor sensors, acoustic microphones or fiber-optic cables) to monitor external pipeline parameters.\n",
    "\n",
    "https://www.researchgate.net/figure/Parameters-of-the-gas_tbl3_265020333\n",
    "https://law.resource.org/pub/us/cfr/ibr/002/api.1130.2002.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read scientific papers on the current best object recognition method\n",
    "\n",
    "#### By : Dirk and Kenneth\n",
    "\n",
    "#### Abstract\n",
    "We want to use machine learning or deep learning techniques to automate the detection of methane leakages that are visible on satellite images. In this chapter we try to find previous work on object recognition methods that may be helpful. The goal is to find the best suitable algorithm to use.\n",
    "\n",
    "#### Article 1\n",
    "\n",
    "This paper talks a lot about feature extraction, which is of course a very important part. After that, simple classification or clustering methods can be used to separate the positives and negatives. Hough-transform is a popular technique of which robustness is a key advantage. It’s also fairly computationally efficient. PCA was mentioned.\n",
    "\n",
    "Summary\n",
    "A lot of reviews categorize object detection techniques in “model-based”, “shape-based” and “appearance-based” (page 2). If we do that, “appearance-based” sounds like the best solution.\n",
    "Another way of categorizing is global and local. This is what’s said about local based: “Local methods search for salient regions or points that characterise the object of interest such as corners, edges or entropy. Later, these re- gions are typified by given descriptors. The local descriptors of the object of interest and the local descriptors of the test image are then compared for object recognition purposes.” This looks like a good approach.\n",
    "\n",
    "Within local-appearance-based detection. You can have different features that describe an object. Corner based or region based. Corner-based does not look good because the corners in our features might be dim and can have all types of shapes.\n",
    "Region based detectors locate local blobs of uniform brightness and are therefore suited for uniform regions or regions with smooth transitions.\n",
    "\n",
    "#### Article 2\n",
    "This paper is focused on salient object detection, which is defined as detecting and segmenting salient objects from natural scenes. We survey i) roots, key concepts, and tasks, ii) core techniques and main modeling trends, and iii) datasets and evaluation metrics for salient object detection. \n",
    "Salient object detection or salient object segmentation is commonly interpreted in computer vision as a process that includes two stages: \n",
    "1) detecting the most salient object: This first stage does not necessarily need to be limited to only one object. The majority of existing models, however, attempt to segment the most salient object, although their prediction maps can be used to find several objects in a scene. \n",
    "\n",
    "2) segmenting the accurate region of that object: This second stage falls into the realm of classic segmentation problems in computer vision but with the difference that here, accuracy is only determined by the most salient object. \n",
    "In addition to color uniqueness, distinctiveness of complementary cues such as texture  and structure are also considered for salient object detection.\n",
    "\n",
    "Summary\n",
    "In general, it is agreed that for good saliency detection a model should meet at least the following three criteria: 1) good detection: the probability of missing real salient regions and falsely marking the background as a salient region should be low, 2) high resolution: saliency maps should have high or full resolution to accurately locate salient objects and retain original image information, and 3) computational efficiency: as front-ends to other complex processes, these models should detect salient regions quickly. \n",
    "Fixation prediction models, on the other hand, typically try to predict where humans look, i.e., a small set of fixation points \n",
    "A key step in detecting salient objects is to distinguish them from distractors. \n",
    "Finally, salient regions are selected by measuring feature contrast and geometric properties of regions.\n",
    "\n",
    "\n",
    "\n",
    "References\n",
    " Fernandez Robles, Laura 2016 Object recognition techniques in real applications\n",
    "https://www.rug.nl/research/portal/files/27921567/Chapter_2.pdf\n",
    "\n",
    "Zhong-Qiu Zhao, Member, IEEE, Peng Zheng, Shou-tao Xu, and Xindong Wu, Fellow, IEEE, 2019. Object Detection with Deep Learning: A Review\n",
    "https://arxiv.org/pdf/1807.05511.pdf\n",
    "\n",
    "Ali Borji, Ming-Ming Cheng, Qibin Hou, Huaizu Jiang, and Jia Li 2019  Salient object detection: A survey\n",
    "https://link.springer.com/content/pdf/10.1007/s41095-019-0149-9.pdf\n",
    "\n",
    "[1] Parthasarathi Roy, 2007 Atmospheric smog modeling, using EOS Satellite ASTER Image Sensor, with feature extraction for pattern recognition techniques and its correlation with In-situ ground sensor data\n",
    "https://mds.marshall.edu/cgi/viewcontent.cgi?referer=https://scholar.google.com/scholar?start=10&q=pattern+recognition+satellite+data+methane&hl=nl&as_sdt=0,5&httpsredir=1&article=1817&context=etd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research on methods of reading satellite image\n",
    "\n",
    "#### By Charmy and Samir\n",
    "\n",
    "Goal of assignment: After NO2 TROPOMI data has been visualised, we need to interpret the data. \n",
    "Link articles image processing\n",
    "\n",
    "https://www.researchgate.net/publication/220413797_An_Unsupervised_Artificial_Neural_Network_Method_for_Satellite_Image_Segmentation\n",
    "Summary: Image segmentation is an essential step in image processing. The goal of segmentation is to simplify to change the representation of an image into a form easier to analyze. \n",
    "Self organizing map (SOM) is used to organize pixels according to grey levels of multiple bands into groups then a threshold technique is used to cluster the image into disjoint regions, this new method is called TSOM.\n",
    "SOM -  Converts patterns of arbitrary dimensionality into the responses of two dimensional arrays of neurons.  It consists of two layers: an input layer and an output layer. The number of input neurons is equal to the dimensions of the input data. The output neurons are, however, arranged in a two-dimensional array. Each input is fully connected to all units. The initial weights are random and small, and their contribution for the final state decreases with the decrease of the number of samples . The network is composed of an orthogonal grid of cluster units (neurons), each is associated with three internal weights for the three layers of the satellite image. At each step in the training phase, the cluster unit with weights that best match the input pattern is elected as the winner usually by using minimum euclidean distance. After the SOM neural network converges to a balance state, the original image is mapped from a high color space to a smaller color space. The number of colors in this space is equal to the number of neurons of the SOM network. The final weights vectors in the map as the new sample space. This new data set is used for clustering, and allows determining a set of cluster centers. \n",
    "T- cluster - to eliminate small clusters which has fewer pixels T cluster eliminates over segmentation problem. After obtaining cluster centers by SOM, cluster processing starts by calculating the distance , where the clusters are combined if their distance between centres is less than predefined threshold T. If this is true then the clusters are combined with the large one. The value of the final cluster is the cluster with the higher number of pixels.\n",
    "TSOM - Now the combination of SOM and T-cluster works sequentially to complete the segmentation process. SOM uses satellite image features to organize pixels in groups. The highest peaks of the histogram are used as cluster centers and are provided to T-Cluster to deliver the final solution in the image segmentation process. \n",
    "TSOM is the best unsupervised neural network as it gives better results according to the experiment conducted in the paper and its two times faster when compared to ISODATA.\n",
    "\n",
    "\n",
    "\n",
    "Article 2: Satellite Image Interpretation using Spatial Reasoning http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.39.6506&rep=rep1&type=pdf\n",
    "Summary: \n",
    "Currently, interpretation of satellite data is done mainly manually by comparing previous geographic maps with updated ones. Here, based on experience of data analysts and background information and contextual information about the problem, a conclusion is made about the data. This is feasible for small sets of data, but becomes a tedious task for bigger sets of data. \n",
    "Proposed solutions in article:\n",
    "Extract features by classification such as crop fields, bare soils, grassy areas and houses;\n",
    "A knowledge-based system to detect shapes in the data;\n",
    "Qualitative representation of positional information. Spatial relations are divided in 2 classes: topological relations and orientation relations. Topological relations: How boundaries of 2 objects relate to each other, while orientation relation describes where objects are placed. For orientation relations, the object is divided into 8 parts. Then, based on changes in orientation, we can reason about it. \n",
    "\n",
    "Summary: 8 different types of algorithms suitable:  Parallelepiped, Minimum distance, Maximum Likelihood, Decision tree method, Support Vector Machine, K Nearest Neighbor Classifier, Artificial Neural network ,Genetic Algorithmic approach.\n",
    "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.735.6733&rep=rep1&type=pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Think about the necessity of feature extraction and how to apply classification\n",
    "\n",
    "#### By: Charmy and Dirk\n",
    "\n",
    "The selected input data, L2 CH4 , contains the concentrations at a certain location at a certain time. We think this is already a feature we can use.\n",
    "\n",
    "\n",
    "Application of classification algorithm\n",
    "We think pursuing a convolutional neural network (CNN) approach is a good idea because it’s been broadly implemented already.\n",
    "\n",
    "Faster RCNN looks like a good candidate https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/\n",
    "YOLO https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf\n",
    "\n",
    "\n",
    "In the first YOLO paper they talk about combining Fast-RCNN with YOLO. This makes it the 4th most accurate object detector on VOC dataset and the only one in that same list that has real-time performance. This is an older paper. Maybe the newer YOLO papers have even better suggestions.\n",
    "\n",
    "\n",
    "Fast-YOLO\n",
    "https://arxiv.org/pdf/1709.05943.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the dataset between L1B and L2 CH4\n",
    "\n",
    "#### By: Abhirup and Charmy\n",
    "\n",
    "We chose the L2 CH4 data set.\n",
    "\n",
    "Reason : L2 CH4 data set is more suitable as it is a processed dataset. It contains methane data exclusively.\n",
    "Whereas L1B data set is more like a raw data set which consists of a combination of data like the UV, SWIR and NIR so filtering the data for methane will be a challenging process. And for this project we are more focused on the methane data exclusively where L2 CH4 is the best option.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
